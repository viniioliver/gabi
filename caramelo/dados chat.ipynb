{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lendo arquivo: 201.csv\n",
      "Erro ao processar 201.csv: [Errno 2] No such file or directory: '201.csv'\n",
      "Lendo arquivo: 202.csv\n",
      "Erro ao processar 202.csv: [Errno 2] No such file or directory: '202.csv'\n",
      "Lendo arquivo: 211.csv\n",
      "Erro ao processar 211.csv: [Errno 2] No such file or directory: '211.csv'\n",
      "Lendo arquivo: 212.csv\n",
      "Erro ao processar 212.csv: [Errno 2] No such file or directory: '212.csv'\n",
      "Lendo arquivo: 221.csv\n",
      "Erro ao processar 221.csv: [Errno 2] No such file or directory: '221.csv'\n",
      "Lendo arquivo: 222.csv\n",
      "Erro ao processar 222.csv: [Errno 2] No such file or directory: '222.csv'\n",
      "Lendo arquivo: 231.csv\n",
      "Erro ao processar 231.csv: [Errno 2] No such file or directory: '231.csv'\n",
      "Lendo arquivo: 232.csv\n",
      "Erro ao processar 232.csv: [Errno 2] No such file or directory: '232.csv'\n",
      "Lendo arquivo: 241.csv\n",
      "Erro ao processar 241.csv: [Errno 2] No such file or directory: '241.csv'\n",
      "Lendo arquivo: 242.csv\n",
      "Erro ao processar 242.csv: [Errno 2] No such file or directory: '242.csv'\n",
      "Nenhum DataFrame foi carregado. Verifique os arquivos e filtros.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No objects to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 36\u001b[39m\n\u001b[32m     33\u001b[39m     \u001b[38;5;28mprint\u001b[39m(df.head())\n\u001b[32m     35\u001b[39m \u001b[38;5;66;03m# Depois, se quiser concatenar todos num DataFrame só:\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlista_vazia\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     37\u001b[39m \u001b[38;5;28mprint\u001b[39m(df.head())\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Program Files\\Python311\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:382\u001b[39m, in \u001b[36mconcat\u001b[39m\u001b[34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[39m\n\u001b[32m    379\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m copy \u001b[38;5;129;01mand\u001b[39;00m using_copy_on_write():\n\u001b[32m    380\u001b[39m     copy = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m382\u001b[39m op = \u001b[43m_Concatenator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    383\u001b[39m \u001b[43m    \u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    384\u001b[39m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    385\u001b[39m \u001b[43m    \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    386\u001b[39m \u001b[43m    \u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m=\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    387\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    388\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlevels\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    389\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnames\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    390\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverify_integrity\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverify_integrity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    391\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    392\u001b[39m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[43m=\u001b[49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    393\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    395\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m op.get_result()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Program Files\\Python311\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:445\u001b[39m, in \u001b[36m_Concatenator.__init__\u001b[39m\u001b[34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[39m\n\u001b[32m    442\u001b[39m \u001b[38;5;28mself\u001b[39m.verify_integrity = verify_integrity\n\u001b[32m    443\u001b[39m \u001b[38;5;28mself\u001b[39m.copy = copy\n\u001b[32m--> \u001b[39m\u001b[32m445\u001b[39m objs, keys = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_clean_keys_and_objs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    447\u001b[39m \u001b[38;5;66;03m# figure out what our result ndim is going to be\u001b[39;00m\n\u001b[32m    448\u001b[39m ndims = \u001b[38;5;28mself\u001b[39m._get_ndims(objs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Program Files\\Python311\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:507\u001b[39m, in \u001b[36m_Concatenator._clean_keys_and_objs\u001b[39m\u001b[34m(self, objs, keys)\u001b[39m\n\u001b[32m    504\u001b[39m     objs_list = \u001b[38;5;28mlist\u001b[39m(objs)\n\u001b[32m    506\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(objs_list) == \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m507\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mNo objects to concatenate\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    509\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m keys \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    510\u001b[39m     objs_list = \u001b[38;5;28mlist\u001b[39m(com.not_none(*objs_list))\n",
      "\u001b[31mValueError\u001b[39m: No objects to concatenate"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from io import StringIO\n",
    "\n",
    "dados = ['201.csv','202.csv','211.csv','212.csv','221.csv','222.csv','231.csv','232.csv','241.csv','242.csv']\n",
    "lista_vazia = []\n",
    "\n",
    "for arquivo in dados:\n",
    "    try:\n",
    "        print(f\"Lendo arquivo: {arquivo}\")\n",
    "        with open(arquivo, 'r', encoding='utf-8') as f:\n",
    "            linhas = f.readlines()\n",
    "\n",
    "        num_campos_esperados = linhas[0].count(';') + 1\n",
    "        linhas_validas = [linha for linha in linhas if linha.count(';') + 1 == num_campos_esperados]\n",
    "        print(f\"Linhas totais: {len(linhas)} - Linhas válidas: {len(linhas_validas)}\")\n",
    "\n",
    "        if len(linhas_validas) == 0:\n",
    "            print(f\"Nenhuma linha válida encontrada em {arquivo}, pulando arquivo.\")\n",
    "            continue\n",
    "\n",
    "        csv_filtrado = StringIO(''.join(linhas_validas))\n",
    "        df_temp = pd.read_csv(csv_filtrado, sep=';', low_memory=False)\n",
    "        lista_vazia.append(df_temp)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao processar {arquivo}: {e}\")\n",
    "        pass\n",
    "\n",
    "if len(lista_vazia) == 0:\n",
    "    print(\"Nenhum DataFrame foi carregado. Verifique os arquivos e filtros.\")\n",
    "else:\n",
    "    df = pd.concat(lista_vazia, ignore_index=True)\n",
    "    print(df.head())\n",
    "\n",
    "# Depois, se quiser concatenar todos num DataFrame só:\n",
    "df = pd.concat(lista_vazia, ignore_index=True)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m df[\u001b[33m'\u001b[39m\u001b[33mData Coleta\u001b[39m\u001b[33m'\u001b[39m] = pd.to_datetime(\u001b[43mdf\u001b[49m[\u001b[33m'\u001b[39m\u001b[33mData da Coleta\u001b[39m\u001b[33m'\u001b[39m], \u001b[38;5;28mformat\u001b[39m=\u001b[33m'\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m/\u001b[39m\u001b[33m%\u001b[39m\u001b[33mm/\u001b[39m\u001b[33m%\u001b[39m\u001b[33mY\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      2\u001b[39m df[\u001b[33m'\u001b[39m\u001b[33mAno-Mês\u001b[39m\u001b[33m'\u001b[39m] = df[\u001b[33m'\u001b[39m\u001b[33mData Coleta\u001b[39m\u001b[33m'\u001b[39m].dt.to_period(\u001b[33m'\u001b[39m\u001b[33mM\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df['Data Coleta'] = pd.to_datetime(df['Data da Coleta'], format='%d/%m/%Y')\n",
    "df['Ano-Mês'] = df['Data Coleta'].dt.to_period('M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Converter coluna de data para datetime e criar coluna Ano-Mês\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m df[\u001b[33m'\u001b[39m\u001b[33mData Coleta\u001b[39m\u001b[33m'\u001b[39m] = pd.to_datetime(\u001b[43mdf\u001b[49m[\u001b[33m'\u001b[39m\u001b[33mData da Coleta\u001b[39m\u001b[33m'\u001b[39m], \u001b[38;5;28mformat\u001b[39m=\u001b[33m'\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m/\u001b[39m\u001b[33m%\u001b[39m\u001b[33mm/\u001b[39m\u001b[33m%\u001b[39m\u001b[33mY\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      3\u001b[39m df[\u001b[33m'\u001b[39m\u001b[33mAno-Mês\u001b[39m\u001b[33m'\u001b[39m] = df[\u001b[33m'\u001b[39m\u001b[33mData Coleta\u001b[39m\u001b[33m'\u001b[39m].dt.to_period(\u001b[33m'\u001b[39m\u001b[33mM\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# 1. Evolução mensal do preço médio da gasolina por estado\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# Converter coluna de data para datetime e criar coluna Ano-Mês\n",
    "df['Data Coleta'] = pd.to_datetime(df['Data da Coleta'], format='%d/%m/%Y')\n",
    "df['Ano-Mês'] = df['Data Coleta'].dt.to_period('M')\n",
    "\n",
    "# 1. Evolução mensal do preço médio da gasolina por estado\n",
    "evolucao_gasolina = df.loc[df['Produto'] == 'GASOLINA COMUM', :].groupby(['Estado - Sigla', 'Ano-Mês'])['Valor de Venda'].mean().reset_index()\n",
    "\n",
    "# 2. Comparação entre gasolina comum e aditivada\n",
    "comparativo = df.loc[df['Produto'].isin(['GASOLINA COMUM', 'GASOLINA ADITIVADA']), :].groupby(['Produto', 'Ano-Mês'])['Valor de Venda'].mean().reset_index()\n",
    "\n",
    "# 3. Análise de variação de preços por região\n",
    "regioes = {\n",
    "    'N': ['AC', 'AP', 'AM', 'PA', 'RO', 'RR', 'TO'],\n",
    "    'NE': ['AL', 'BA', 'CE', 'MA', 'PB', 'PE', 'PI', 'RN', 'SE'],\n",
    "    'CO': ['DF', 'GO', 'MT', 'MS'],\n",
    "    'SE': ['ES', 'MG', 'RJ', 'SP'],\n",
    "    'S': ['PR', 'RS', 'SC']\n",
    "}\n",
    "\n",
    "def estado_para_regiao(sigla):\n",
    "    for regiao, estados in regioes.items():\n",
    "        if sigla in estados:\n",
    "            return regiao\n",
    "    return 'Outro'\n",
    "\n",
    "df['Região'] = df['Estado - Sigla'].apply(estado_para_regiao)\n",
    "\n",
    "variacao_regiao = df.loc[df['Produto'] == 'GASOLINA COMUM', :].groupby(['Região', 'Ano-Mês'])['Valor de Venda'].mean().reset_index()\n",
    "\n",
    "# 4. Postos com maiores e menores preços (gasolina comum)\n",
    "postos_extremos = df.loc[df['Produto'] == 'GASOLINA COMUM', ['Revenda', 'Municipio', 'Estado - Sigla', 'Valor de Venda']]\n",
    "\n",
    "maiores_precos = postos_extremos.sort_values(by='Valor de Venda', ascending=False).head(10)\n",
    "menores_precos = postos_extremos.sort_values(by='Valor de Venda').head(10)\n",
    "\n",
    "# Perguntas analíticas\n",
    "\n",
    "# Estado com maior variação entre 2020 e 2024\n",
    "df_gas = df.loc[df['Produto'] == 'GASOLINA COMUM', :].copy()\n",
    "df_gas['Ano'] = df_gas['Data Coleta'].dt.year\n",
    "\n",
    "inicio_fim = df_gas.loc[df_gas['Ano'].isin([2020, 2024]), :].groupby(['Estado - Sigla', 'Ano'])['Valor de Venda'].mean().unstack()\n",
    "inicio_fim['Variação (%)'] = ((inicio_fim[2024] - inicio_fim[2020]) / inicio_fim[2020]) * 100\n",
    "maior_var = inicio_fim.sort_values(by='Variação (%)', ascending=False).head(1)\n",
    "\n",
    "# Estados onde o etanol é competitivo (< 70% do preço da gasolina)\n",
    "media_precos = df.loc[df['Produto'].isin(['GASOLINA COMUM', 'ETANOL']), :].groupby(['Estado - Sigla', 'Produto'])['Valor de Venda'].mean().unstack()\n",
    "media_precos['Proporção'] = media_precos['ETANOL'] / media_precos['GASOLINA COMUM']\n",
    "estados_competitivos = media_precos.loc[media_precos['Proporção'] < 0.7, :]\n",
    "\n",
    "# Diferença significativa entre preços das distribuidoras (gasolina comum)\n",
    "df_dist = df.loc[df['Produto'] == 'GASOLINA COMUM', :]\n",
    "media_dist = df_dist.groupby('Distribuidora')['Valor de Venda'].mean().reset_index().sort_values(by='Valor de Venda', ascending=False)\n",
    "\n",
    "# Resultados básicos\n",
    "print(\"Evolução mensal da gasolina por estado:\")\n",
    "print(evolucao_gasolina.head())\n",
    "\n",
    "print(\"\\nComparação gasolina comum e aditivada:\")\n",
    "print(comparativo.head())\n",
    "\n",
    "print(\"\\nVariação por região:\")\n",
    "print(variacao_regiao.head())\n",
    "\n",
    "print(\"\\nPostos com maiores preços (Gasolina comum):\")\n",
    "print(maiores_precos)\n",
    "\n",
    "print(\"\\nPostos com menores preços (Gasolina comum):\")\n",
    "print(menores_precos)\n",
    "\n",
    "print(\"\\nEstado com maior variação percentual na gasolina (2020-2024):\")\n",
    "print(maior_var)\n",
    "\n",
    "print(\"\\nEstados onde etanol é competitivo (menos de 70% do preço da gasolina):\")\n",
    "print(estados_competitivos)\n",
    "\n",
    "print(\"\\nMédia de preços por distribuidora (Gasolina comum):\")\n",
    "print(media_dist.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
